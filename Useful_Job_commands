sbatch -c 8 -p huce_intel -t 100 --mem=20000 --wrap='make; make install -j 8'


SHOW JOBs:
  sacct -P -S <START_TIME .e.g 0808>
  
Interactive Jobs:
  srun -p test --pty -n 4 -N 1 --mem 20000 -t 0-06:00 /bin/bash
  
  salloc -p huce_intel -n 1 -t 0-12:00 --mem=30000
  ssh -Y $SLURM_JOB_NODELIST
  
SUBMIT JOBs:
  sbatch <--test-only> -N <max numbers> --contiguous <bash_script.sh>
  ## Use contiguous cores will greatly improve efficiency.
  ## N=30 for 900 cores 5km
  ## N=12 for 360 cores 10km

SHOW NODES:
  use "~pchan/bin/lsload.pl huce_intel"
  to show current 'node-level' status of non-full nodes in huce partitions
  

